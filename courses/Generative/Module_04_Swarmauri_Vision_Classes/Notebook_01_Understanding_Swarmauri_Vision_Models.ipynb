{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Understanding Swarmauri Vision Models**  \n",
    "---\n",
    "\n",
    "In this notebook, we’ll explore the various **Vision Models** provided by Swarmauri and their capabilities.  \n",
    "\n",
    "We’ll also cover:  \n",
    "- How to view the supported vision models.  \n",
    "- The methods available in these classes and how to use them effectively.  \n",
    "\n",
    "This notebook is a concise guide to understanding and working with Swarmauri’s Vision Models to streamline your AI-powered visual analysis tasks.  \n",
    "\n",
    "---\n",
    "\n",
    "## **What Are Vision Models?**  \n",
    "\n",
    "Vision models are AI systems designed to analyze and process visual data such as images or videos. They leverage deep learning techniques to extract meaningful insights, enabling applications across diverse industries.  \n",
    "\n",
    "### **Use Cases of Vision Models**  \n",
    "\n",
    "1. **Object Detection and Recognition**  \n",
    "   - Identifying and classifying objects in images or videos.  \n",
    "   - Detecting faces, vehicles, or other specific items for real-time applications.  \n",
    "\n",
    "2. **Image Segmentation**  \n",
    "   - Separating images into distinct regions for medical imaging or autonomous driving.  \n",
    "\n",
    "3. **Content Moderation**  \n",
    "   - Detecting inappropriate or restricted content in media platforms.  \n",
    "\n",
    "4. **Retail and E-Commerce**  \n",
    "   - Visual search for products based on user-uploaded images.  \n",
    "\n",
    "5. **Accessibility**  \n",
    "   - Converting images into text for visually impaired users.  \n",
    "\n",
    "By leveraging these capabilities, Swarmauri Vision Models empower users to solve complex problems efficiently.  \n",
    "\n",
    "With this understanding, let’s dive deeper into the specific Vision Models provided by Swarmauri and the functionalities they offer. \n",
    "\n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Vision Classes in Swarmauri\n",
    "---\n",
    "\n",
    "Swarmauri provides the following Vision classes, named based on the providers of the models:\n",
    "\n",
    "1. **FalAIVisionModel**:  \n",
    "2. **GroqVisionModel**:  \n",
    "3. **HyperbolicVisionModel**: \n",
    "\n",
    "### Provider Naming Convention  \n",
    "Swarmauri follows a *provider naming convention*. This means that the file and class names reflect the **provider** of the providers of the Vision models and not the actual vision model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to see the Allowed Models in Vision class\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ### Import the class \n",
    "\n",
    "- Here we will `FalAIVisionModel`, you can use any other class of your choice from the List of `Vision` Classes in Swarmauri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarmauri.llms.concrete.FalAIVisionModel import FalAIVisionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ### Instantiate the Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FalAIVisionModel(api_key=\"put your api key here\") # Note: You don't need an API key to see the allowed_model, you can leave it as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ### List all available models\n",
    "- To list the allowed models, we use the `allowed_models` class attribute, just like we did when working with LLMs and Image Generation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fal-ai/llava-next']\n"
     ]
    }
   ],
   "source": [
    "available_models = model.allowed_models\n",
    "print(available_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `FalAIVision` has one allowed model for now and it has been printed.  \n",
    "\n",
    "This approach is similar to how we worked with LLMs and Image Generation Models earlier. Swarmauri ensures consistency by allowing you to use the same methods and attributes across different classes in a unified manner. This design simplifies the process, making it more intuitive and efficient to build with Swarmauri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods Available in Each Vision Model Class  \n",
    "---\n",
    "\n",
    "Each **Vision Model** class in **Swarmauri** offers a set of methods designed to streamline interactions with the models. These methods provide flexibility for **synchronous**, **asynchronous**, and **streaming** workflows, catering to various use cases in visual analysis.  \n",
    "\n",
    "1. **`predict`**:  \n",
    "   - **Description**: This method performs visual analysis synchronously (blocking).  \n",
    "   - **Use Case**: When you need immediate results from a single vision model request.  \n",
    "\n",
    "2. **`apredict`**:  \n",
    "   - **Description**: The asynchronous counterpart of `predict`. It processes visual data without blocking the program.  \n",
    "   - **Use Case**: When running multiple tasks concurrently using `asyncio`.  \n",
    "\n",
    "3. **`stream`**:  \n",
    "   - **Description**: Streams results incrementally as the vision model processes the data.  \n",
    "   - **Use Case**: When working with large or time-sensitive visual data that requires real-time feedback.  \n",
    "\n",
    "4. **`astream`**:  \n",
    "   - **Description**: The asynchronous version of `stream`. It streams results while allowing other tasks to run concurrently.  \n",
    "   - **Use Case**: When processing large datasets in an asynchronous environment and need real-time updates.  \n",
    "\n",
    "These methods provide comprehensive support for both single and streaming workflows, ensuring that you can adapt to any use case involving vision models in Swarmauri. This flexibility empowers you to handle everything from immediate predictions to real-time visual analysis with ease.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NOTEBOOK METADATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Victory Nnaji\n",
      "GitHub Username: 3rd-Son\n",
      "Notebook File: Notebook_01_Understanding_Swarmauri_Vision_Models.ipynb\n",
      "Last Modified: 2024-12-24 13:13:17.363559\n",
      "Platform: Darwin 24.1.0\n",
      "Python Version: 3.11.11 (main, Dec 11 2024, 10:25:04) [Clang 14.0.6 ]\n",
      "Swarmauri Version: 0.5.2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from swarmauri.utils import print_notebook_metadata\n",
    "\n",
    "metadata = print_notebook_metadata.print_notebook_metadata(\"Victory Nnaji\", \"3rd-Son\")\n",
    "print(metadata) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

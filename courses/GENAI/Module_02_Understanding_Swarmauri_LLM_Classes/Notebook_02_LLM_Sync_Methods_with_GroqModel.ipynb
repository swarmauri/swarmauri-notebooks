{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLM Sync Methods with GroqModel**\n",
    "\n",
    "## **Introduction:**\n",
    "\n",
    "Groq provides a suite of powerful **open source Large Language Models (LLMs)** optimized for speed and efficiency, enabling advanced text generation and conversational tasks. Groq's models, such as *Gemma-7b-it*, *LLaMA*, and *mixtral-8x7b-32768*, are designed for developers who need high-performance, low-latency interactions in their NLP applications. This notebook guides users through setting up and utilizing Groq's LLMs for a variety of use cases, including synchronous text generation, streaming responses, and batch processing. By mastering Groq's models, users can efficiently implement seamless, high-quality interactions across diverse tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook will:**\n",
    "\n",
    "- Introduce setup and initialization for the Groq models within **Swarmauri**.  \n",
    "- Demonstrate **synchronous** text generation, real-time streaming responses, and contextual query handling.  \n",
    "- Provide examples showcasing Groqâ€™s model versatility for conversational AI and batch processing.  \n",
    "\n",
    "By the end of this notebook, you will have a comprehensive understanding of how to use Groq's LLMs to build fast and reliable NLP applications.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup and Configuration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarmauri.llms.concrete.GroqModel import GroqModel  # This is the actual GroqModel class\n",
    "from swarmauri.conversations.concrete.Conversation import Conversation  # For handling conversation logic and flow\n",
    "from swarmauri.messages.concrete.HumanMessage import HumanMessage  # For adding user input or human messages\n",
    "from swarmauri.messages.concrete.SystemMessage import SystemMessage  # For adding system-level instructions (System Prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your API KEY from your environment variables\n",
    "- Make sure you have python-dotenv installed if not, run `pip install python-dotenv` so you can install it.\n",
    "- To get your API KEY, click [HERE](https://console.groq.com/keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Groq Model\n",
    "- Note: You can as well input your api key directly, but it's better to load from env file\n",
    "- Also, the `name` arguments is an optional argument that allows you to input a model from the list of allowed_models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GroqModel(api_key=GROQ_API_KEY, name=\"gemma-7b-it\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Interaction Techniques\n",
    "---\n",
    "\n",
    "### **1. Simple Conversation with only Human Message (User's Message)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(HumanMessage(content=\"Who is the founder of Python Programming Language?.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Guido van Rossum** is the founder of the Python Programming Language.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(conversation=conversation) # The predict method is what gives you the answer\n",
    "print(response.get_last().content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Adding System Context to Your Conversation**\n",
    "\n",
    "System context is a way to provide the model with instructions or background information to guide its behavior and responses. By setting the system context, you can specify the role the model should play, the tone it should adopt, or the particular rules it should follow throughout the conversation. This ensures the model generates responses that align with your intended goals.\n",
    "\n",
    "For example, you can define the system context to:\n",
    "\n",
    "- Act as a customer support assistant.  \n",
    "- Provide responses in a formal or casual tone.  \n",
    "- Stick to a specific topic, like programming or healthcare.  \n",
    "\n",
    "**Below, we will define a system context for a customer support assistant for Amazon, an ecommerce company.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_system_context = \"\"\"\n",
    "You are a customer support assistant for Amazon, a leading e-commerce company.\n",
    "You help users with the following tasks:\n",
    "- Checking order status\n",
    "- Processing returns and refunds\n",
    "- Providing product recommendations\n",
    "- Assisting with account and payment issues\n",
    "- Answering general queries about shipping, deliveries, and policies\n",
    "\n",
    "Always be polite, clear, and concise while providing helpful solutions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.add_message(SystemMessage(content=amazon_system_context))\n",
    "conversation.add_message(HumanMessage(content=\"Hi, which products can I buy at Amazon?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon offers a vast selection of products across various categories, including:\n",
      "\n",
      "**Electronics:**\n",
      "* Laptops\n",
      "* Smartphones\n",
      "* Tablets\n",
      "* TVs\n",
      "* Gaming consoles\n",
      "\n",
      "**Fashion:**\n",
      "* Clothing\n",
      "* Shoes\n",
      "* Jewelry\n",
      "* Handbags\n",
      "* Accessories\n",
      "\n",
      "**Home & Kitchen:**\n",
      "* Furniture\n",
      "* Appliances\n",
      "* Bedding\n",
      "* Kitchenware\n",
      "* Home decor\n",
      "\n",
      "**Toys & Games:**\n",
      "* Toys for all ages\n",
      "* Board games\n",
      "* Video games\n",
      "* Collectibles\n",
      "\n",
      "**Books & Stationery:**\n",
      "* Books\n",
      "* Ebooks\n",
      "* Pens\n",
      "* Paper\n",
      "* Writing supplies\n",
      "\n",
      "**Other categories:**\n",
      "* Tools and hardware\n",
      "* Sports and outdoors gear\n",
      "* Pet supplies\n",
      "* Food and groceries\n",
      "* Health and beauty products\n",
      "\n",
      "**To find what you're looking for:**\n",
      "* Use the search bar on our website.\n",
      "* Browse through our different categories.\n",
      "* Use the filters on our product pages to narrow your search.\n",
      "\n",
      "If you have any questions or need further assistance, please feel free to ask me.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(conversation=conversation)\n",
    "print(response.get_last().content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **3. Advanced Processing Techniques**\n",
    "\n",
    "1. **Streaming Token Generation:**  \n",
    "Using the `stream` method, responses are generated and displayed **token by token** as they are received. This is ideal for real-time applications where partial answers are needed progressively, rather than waiting for the complete response to load.\n",
    "\n",
    "For example, when using ChatGPT, you may notice that answers **appear gradually, word by word**, as the model processes and sends the response. This behavior can be replicated using the `stream` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**\n",
      "Here\n",
      " are\n",
      " some\n",
      " ways\n",
      " to\n",
      " get\n",
      " discounts\n",
      " on\n",
      " Amazon\n",
      ":**\n",
      "\n",
      "\n",
      "\n",
      "**\n",
      "1\n",
      ".\n",
      " Coupons\n",
      " and\n",
      " Promo\n",
      " Codes\n",
      ":**\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      " Check\n",
      " Amazon\n",
      "'\n",
      "s\n",
      " **\n",
      "Coupons\n",
      "**\n",
      " page\n",
      " for\n",
      " ongoing\n",
      " promotions\n",
      " and\n",
      " discounts\n",
      ".\n",
      "\n",
      "\n",
      "*\n",
      " Sign\n",
      " up\n",
      " for\n",
      " Amazon\n",
      "'\n",
      "s\n",
      " **\n",
      "Prime\n",
      " membership\n",
      "**\n",
      " for\n",
      " exclusive\n",
      " discounts\n",
      " and\n",
      " free\n",
      " shipping\n",
      ".\n",
      "\n",
      "\n",
      "*\n",
      " Look\n",
      " for\n",
      " **\n",
      "promo\n",
      " codes\n",
      "**\n",
      " on\n",
      " social\n",
      " media\n",
      ",\n",
      " websites\n",
      ",\n",
      " or\n",
      " in\n",
      " emails\n",
      " from\n",
      " Amazon\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "**\n",
      "2\n",
      ".\n",
      " Sales\n",
      " and\n",
      " Deals\n",
      ":**\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      " Visit\n",
      " the\n",
      " **\n",
      "Amazon\n",
      " Deals\n",
      " page\n",
      "**\n",
      " for\n",
      " daily\n",
      " deals\n",
      " and\n",
      " limited\n",
      "-\n",
      "time\n",
      " offers\n",
      ".\n",
      "\n",
      "\n",
      "*\n",
      " Check\n",
      " the\n",
      " **\n",
      "Weekly\n",
      " Deals\n",
      " email\n",
      "**\n",
      " for\n",
      " personalized\n",
      " discounts\n",
      ".\n",
      "\n",
      "\n",
      "*\n",
      " Keep\n",
      " an\n",
      " eye\n",
      " out\n",
      " for\n",
      " **\n",
      "flash\n",
      " sales\n",
      "**\n",
      " and\n",
      " **\n",
      "clearance\n",
      " items\n",
      "**.\n",
      "\n",
      "\n",
      "\n",
      "**\n",
      "3\n",
      ".\n",
      " Prime\n",
      " Benefits\n",
      ":**\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      " Prime\n",
      " members\n",
      " receive\n",
      " exclusive\n",
      " discounts\n",
      " on\n",
      " millions\n",
      " of\n",
      " items\n",
      ".\n",
      "\n",
      "\n",
      "*\n",
      " Enjoy\n",
      " **\n",
      "free\n",
      " shipping\n",
      "**\n",
      " on\n",
      " eligible\n",
      " orders\n",
      ".\n",
      "\n",
      "\n",
      "*\n",
      " Get\n",
      " access\n",
      " to\n",
      " **\n",
      "Prime\n",
      " Video\n",
      "**,\n",
      " music\n",
      " streaming\n",
      ",\n",
      " and\n",
      " other\n",
      " exclusive\n",
      " benefits\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "**\n",
      "4\n",
      ".\n",
      " Subscribe\n",
      " &\n",
      " Save\n",
      ":**\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      " Subscribe\n",
      " to\n",
      " regular\n",
      " deliveries\n",
      " of\n",
      " your\n",
      " favorite\n",
      " items\n",
      " and\n",
      " get\n",
      " **\n",
      "automatic\n",
      " discounts\n",
      "**.\n",
      "\n",
      "\n",
      "*\n",
      " Choose\n",
      " how\n",
      " often\n",
      " you\n",
      " want\n",
      " to\n",
      " receive\n",
      " items\n",
      " and\n",
      " save\n",
      " up\n",
      " to\n",
      " \n",
      "1\n",
      "5\n",
      "%.\n",
      "\n",
      "\n",
      "\n",
      "**\n",
      "5\n",
      ".\n",
      " Deal\n",
      "Ste\n",
      "alers\n",
      ":**\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      " Amazon\n",
      " often\n",
      " offers\n",
      " **\n",
      "Deal\n",
      "Ste\n",
      "alers\n",
      "**,\n",
      " which\n",
      " are\n",
      " heavily\n",
      " discounted\n",
      " items\n",
      " for\n",
      " a\n",
      " limited\n",
      " time\n",
      ".\n",
      "\n",
      "\n",
      "*\n",
      " Look\n",
      " for\n",
      " the\n",
      " **\n",
      "Deal\n",
      "Ste\n",
      "alers\n"
     ]
    }
   ],
   "source": [
    "human_message = HumanMessage(content=\"How can I get discounts on Amazon?\")\n",
    "conversation.add_message(human_message)\n",
    "\n",
    "collected_tokens = []\n",
    "for token in model.stream(conversation=conversation):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the answers appeared **token by token**, similar to how responses load in a **real-world application**, such as when interacting with ChatGPT or other conversational AI systems. \n",
    "This behavior ensures that partial responses are displayed in **real-time**, providing a smoother and more engaging user experience.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Batch Processing Multiple Conversations**  \n",
    "Imagine you need to send **multiple questions** at once or handle queries from **several users simultaneously**. The `batch` method allows you to process these requests efficiently in a single call, saving time and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = []\n",
    "for prompt in [\"Where is Amazon Store in Texas USA?\", \"How do I cancel an order?\"]:\n",
    "    conv = Conversation()\n",
    "    conv.add_message(HumanMessage(content=prompt))\n",
    "    conversations.append(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to question 1 is:\n",
      "Amazon does not have physical stores in the traditional sense. It is an online retailer.\n",
      "\n",
      "Answer to question 2 is:\n",
      "**Step 1: Contact Customer Support**\n",
      "\n",
      "* Visit our website or call our customer service hotline at [phone number].\n",
      "* Provide the following information:\n",
      "    * Your order number\n",
      "    * Your email address\n",
      "    * The reason for cancellation\n",
      "\n",
      "**Step 2: Confirm Cancellation**\n",
      "\n",
      "* A customer service representative will verify your request and attempt to cancel the order before it is processed.\n",
      "* If the order has already been processed or shipped, cancellation may not be possible.\n",
      "\n",
      "**Step 3: Confirmation of Cancellation**\n",
      "\n",
      "* Once the cancellation is confirmed, you will receive an email notification with the cancellation details.\n",
      "* Please allow 3-5 business days for the refund to be processed.\n",
      "\n",
      "**Additional Notes:**\n",
      "\n",
      "* Cancellation requests are subject to availability and processing time.\n",
      "* If the order has been shipped, cancellation is not guaranteed.\n",
      "* Refunds will be issued to the original payment method used for the order.\n",
      "* Please refer to our [Refund Policy](link to refund policy) for more information.\n",
      "\n",
      "**Note:** The cancellation process may vary depending on the payment method and order status.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_results = model.batch(conversations=conversations)\n",
    "for i, result in enumerate(batch_results, 1):\n",
    "    print(f\"Answer to question {i} is:\")\n",
    "    print(result.get_last().content)\n",
    "    print()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion:**\n",
    "\n",
    "In this notebook, we explored the basic synchronous methods available in Swarmauri's LLM classes. You have learned how to use the `predict`, `stream`, and `batch` methods effectively. Additionally, we demonstrated how to add system context to guide the behavior of the LLMs for specific tasks.\n",
    "\n",
    "**In the next section, we will dive into the asynchronous methods, exploring their unique capabilities and understanding what sets them apart from the synchronous ones.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NOTEBOOK METADATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Victory Nnaji\n",
      "GitHub Username: 3rd-Son\n",
      "Notebook File: Notebook_02_LLM_Sync_Methods_with_GroqModel.ipynb\n",
      "Last Modified: 2024-12-20 10:39:06.323395\n",
      "Platform: Darwin 24.1.0\n",
      "Python Version: 3.11.11 (main, Dec 11 2024, 10:25:04) [Clang 14.0.6 ]\n",
      "Swarmauri Version: 0.5.2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from swarmauri.utils import print_notebook_metadata\n",
    "\n",
    "metadata = print_notebook_metadata.print_notebook_metadata(\"Victory Nnaji\", \"3rd-Son\")\n",
    "print(metadata) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

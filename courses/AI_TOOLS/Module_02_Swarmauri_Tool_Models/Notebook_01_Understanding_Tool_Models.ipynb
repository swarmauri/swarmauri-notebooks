{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Understanding Tool Models**\n",
    "\n",
    "Tool Models are specialized LLMs (Language Models) that can be used for tool calling or function calling. These models are designed to integrate seamlessly with various tools, enabling more dynamic and interactive workflows.  \n",
    "\n",
    "In this notebook, we’ll explore the **LLMs** provided by Swarmauri and learn how to leverage them effectively.  \n",
    "\n",
    "### What You’ll Learn  \n",
    "- How to view the allowed or supported models for each LLM class.  \n",
    "- The methods available in these classes and their purposes.  \n",
    "\n",
    "This notebook serves as a comprehensive guide to understanding and working with Swarmauri’s LLM classes, empowering you to make the most of its advanced features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of LLM Tool Classes in Swarmauri  \n",
    "---\n",
    "Swarmauri provides a collection of LLM classes, each named after its corresponding tool provider. These include:  \n",
    "- **AnthropicToolModel**  \n",
    "- **CohereToolModel**  \n",
    "- **GeminiToolModel**  \n",
    "- **GroqToolModel**  \n",
    "- **MistralToolModel**  \n",
    "- **OpenAIToolModel**  \n",
    "\n",
    "Each class is tailored to support specific LLM providers, offering unique capabilities and methods to suit a variety of use cases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to see the Allowed Models in each LLM Tool class\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ### Import the class \n",
    "\n",
    "- Here we will use MistralToolModel, you can use any other class of your choice from the List of Tool Classes in Swarmauri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarmauri.llms.concrete.MistralToolModel import MistralToolModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ### Instantiate the Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_model = MistralToolModel(api_key=\" your api key here\") # Note: You don't need an API key to see the allowed_model, you can leave it as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ### List all available models\n",
    "- To list the allowed models, we use the `allowed_models` class attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['open-mixtral-8x22b', 'mistral-small-latest', 'mistral-large-latest', 'open-mistral-nemo']\n"
     ]
    }
   ],
   "source": [
    "available_models = tool_model.allowed_models\n",
    "print(available_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this printed the allowed models. You can apply this approach to other classes by importing the respective tool model class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods Available in Each LLM Tool Class  \n",
    "---\n",
    "\n",
    "Each LLM Tool class in **Swarmauri** provides the following methods for interacting with the models. These methods are designed to offer flexibility for both **synchronous** and **asynchronous** workflows, as well as batch processing.  \n",
    "\n",
    "1. **`predict`**:  \n",
    "   - **Description**: This method allows you to interact with the LLM in a synchronous (blocking) way.  \n",
    "   - **Use Case**: When you need immediate results for a single input.  \n",
    "\n",
    "\n",
    "2. **`apredict`**:  \n",
    "   - **Description**: The asynchronous counterpart of `predict`. It allows you to interact with the LLM without blocking the program.  \n",
    "   - **Use Case**: When running multiple tasks concurrently using `asyncio`.  \n",
    "\n",
    "\n",
    "3. **`stream`**:  \n",
    "   - **Description**: Enables streaming responses from the LLM synchronously. This is useful for real-time text generation.  \n",
    "   - **Use Case**: When you want to process or display results as they are generated.  \n",
    "\n",
    "\n",
    "4. **`astream`**:  \n",
    "   - **Description**: Asynchronous streaming of responses. It allows you to stream responses without blocking the program.  \n",
    "   - **Use Case**: For real-time streaming in an asynchronous environment.  \n",
    "\n",
    "\n",
    "5. **`batch`**:  \n",
    "   - **Description**: Allows you to process multiple inputs at once in a synchronous manner.  \n",
    "   - **Use Case**: When you need to send a batch of requests for efficiency.  \n",
    "\n",
    "\n",
    "6. **`abatch`**:  \n",
    "   - **Description**: Asynchronous version of the `batch` method for processing multiple inputs concurrently.  \n",
    "   - **Use Case**: When you need to process a batch of inputs in an asynchronous environment.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table of Methods  \n",
    "\n",
    "| **Method**   | **Type**         | **Description**                                | **Use Case**                          |  \n",
    "|--------------|------------------|-----------------------------------------------|---------------------------------------|  \n",
    "| `predict`    | Synchronous      | Standard single-input LLM interaction.        | Immediate, single input results.      |  \n",
    "| `apredict`   | Asynchronous     | Non-blocking single-input interaction.        | Concurrent tasks with async.          |  \n",
    "| `stream`     | Synchronous      | Streaming responses in real time.             | Real-time output for synchronous use. |  \n",
    "| `astream`    | Asynchronous     | Streaming responses asynchronously.           | Real-time async output.               |  \n",
    "| `batch`      | Synchronous      | Processes multiple inputs synchronously.      | Batch processing for efficiency.      |  \n",
    "| `abatch`     | Asynchronous     | Processes multiple inputs asynchronously.     | Async batch processing.               |  \n",
    "\n",
    "These methods provide the necessary tools for diverse workflows, whether you need synchronous, asynchronous, or batch interactions with the tool LLM.  \n",
    "\n",
    "Sit tight for the next part, where we'll dive into the implementation details of these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NOTEBOOK METADATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Victory Nnaji\n",
      "GitHub Username: 3rd-Son\n",
      "Notebook File: Notebook_01_Understanding_Tool_Models.ipynb\n",
      "Last Modified: 2024-12-24 09:11:55.130987\n",
      "Platform: Darwin 24.1.0\n",
      "Python Version: 3.11.11 (main, Dec 11 2024, 10:25:04) [Clang 14.0.6 ]\n",
      "Swarmauri Version: 0.5.2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from swarmauri.utils import print_notebook_metadata\n",
    "\n",
    "metadata = print_notebook_metadata.print_notebook_metadata(\"Victory Nnaji\", \"3rd-Son\")\n",
    "print(metadata) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
